# -*- coding: utf-8 -*-
"""
Created on Thu May 29 11:29:32 2014

@author: chiaracasotto
"""
import numpy as np
import scipy.stats as stat
import os
import matplotlib.pyplot as plt
pi = 3.141592653589793

def DFfragility(T, Gamma, drlim, SPO, bUthd, mc, r, g, Tc, Td, MC):
#------------------------------------------------------------------------------    
# INPUT
# Cy     : base shear coefficient at yield (presently covered by Gamma and dry)
#          Cy = Say/g = Vy/W, where Say=Sa @ yield, Vy = base shear @ yield
# drlim  : median roof displacement value that defines the fragility. It can result 
#          from any EDP but it should be expressed in terms of the (median)
#          corresponding roof disp (just like we always do in pushovers anyway)
# dry    : roof yield displacement
# buthd  : dispersion (std of log data) characterizing the lognormal
#          distribution of "limit-state roof drift capacity" around drlim
# T      : ESDOF period (sec)
# Gamma  : the participation factor for the roof displacement(>1). Note that for
#          a tall building (or higher-mode influenced one) it is best if you get
#          this value from Say versus droofy estimated from modal response
#          spectrum analysis to include multiple modes. If you use the Gamma of
#          the first one only you will not do well enough (it tends to be
#          lower). See work of Katsanos & Vamva (2014). 
# Tc,Td  : constant accel-constant velocity  and constant velocity-constant
#          displacement corner periods of a Newmark-Hall type spectrum. Default
#          values (roughly taken from Dolsek & Fafjar's (2005) third set of
#          ground motions), are [0.5,1.8].
# mc     : end-of-plastic-plateau capping ductility.
# r      : residual plateau strength divided by yield strength
#
# g      : the value of "g" in units compatible with T and drlim, dry.
#          The default is 9.81m/s2, assuming that dry and drlim are in meters.
# OUTPUT
# Sa50   : the median Sa for the fragility, in units of "g"
# bTSa   : the total dispersion, including capacity and demand dispersions.
#------------------------------------------------------------------------------ 
    if r>1:
        print 'Error: rp should be less than 1'
        os._exit(1)
    if r<0.25:
        print 'Warning: rp should be higher than 0.25, but let us proceed'
    if mc<1:
        print 'Error: mc should be higher than 1'
        os._exit(1)
    if mc>2.5:
        print 'warning: mc should be lower than 2.5, but let us proceed'
    
    dry, du = SPO[0], SPO[-3]
    drlim = np.array(drlim)
    drlim[drlim>du]=du
    mlim=drlim/dry
    
    if mlim.any()>10: 
        print 'Error: mlim should be less than 10,but let us proceed'
    
    # <codecell>
    
    # For a given period, the IDA model is bilinear (piecewise linear with 2
    # segments)in the post-yield range.
    # In other words it provides a trilinear approximation for the mean IDA (mean mu
    # given R). The point where this change happens is [mc,Rmc].
    # So the mean IDA is defined by 4 points total and 3 segments (incl. elastic):
    # Elastic segment: [0,0] -> [1,1]
    #                  Note though the improvement suggested in D&F (2006) that is
    #                  not adopted here.
    # Capping segment: [1,1] -> [mc,Rmc]
    # Post-capping   : [mc,Rmc] -> [mf,Rmf]
    #                  where the final point is selected by some arbitrary
    #                  Rmf>Rmc, mf=function of Rmf.
    # Thus, to get the mean IDA, I only need mf and Rmf (in addition to mc,Rmc).
    
    # Get the (mc50, Rmc) point
    Tdstar=Td*np.sqrt(2-r)
    R0=1
    m0=1
    # Eq. 2 and 3 in Dolsek and Fajfar (2004)
    if T<=Tc:
        c=0.7*(T/Tc)
    elif T<=Tdstar:
        DT=(T-Tc)/(Tdstar-Tc)
        c=(0.7 + 0.3*DT)
    else:
        c=1
    Rmc = c*(mc-m0) + R0
    
    # from Ruiz-Garcia and Miranda (2007)
    # RGM2007 was fit up to an R=6. Find the largest beta for this period given
    # that R=6 and make sure you do not exceed it.
    R6 = 6
    bthd_max=1.957*(1/5.876+1/(11.749*(T+0.1)))*(1-np.exp(-0.739*(R6-1)));
    
    # find the capping point on the IDA curve.
    if Rmc<=R6:
        bthd_mc=1.957*(1/5.876 + 1/(11.749*(T+0.1)))*(1-np.exp(-0.739*(Rmc-1)))
    else:
        # too large Rmc, cap its dispersion by the max fitted by RGM2007
        bthd_mc=bthd_max
    
    # Get median and fractiles. For lognormal: Median = mean * exp(0.5*sigma^2)
    mc50=mc/np.exp(0.5*np.power(bthd_mc,2))
    mc16=mc50*np.exp(-bthd_mc)
    mc84=mc50*np.exp(bthd_mc)
    
    # <codecell>
    
    # Now set Rmf as twice Rmc and get (mf50,Rmf) point. No real reason why I am using
    # double the value, but since the approximation is linear here, I can
    # interpolate or extrapolate as needed and be fine, so the actual value of Rmf
    # does not matter, as long as the slope Rmf/mf is right.
    Rmf=max(2*Rmc,6)
    R0=Rmc
    m0=mc
    if T<=Tc:
        c=0.7*np.sqrt(r)*np.power((T/Tc),(1/np.sqrt(r)))
    elif T<=Tdstar:
        c=0.7*np.sqrt(r)*(1-DT)+DT
    else:
        c=1
    # This is the mean mu given R at the ficticious Rmf point used to define the
    # post-capping segment.
    mf_mean=(Rmf-R0)/c + m0
    #bthd_mf=1.957*(1/5.876 + 1/(11.749*(T + 0.1)))*(1-np.exp(-0.739*(Rmf - 1)))
    bthd_mf = bthd_max;
    # For lognormal: Median = mean * exp(0.5*sigma^2)
    mf50=mf_mean/np.exp(0.5*np.power(bthd_mf,2))
    mf16=mf50*np.exp(-bthd_mf)
    mf84=mf50*np.exp(bthd_mf)
    
    # <codecell>
    
    R=[0,1,Rmc,Rmf]
    mu16=[0,1,mc16,mf16]
    mu50=[0,1,mc50,mf50]
    mu84=[0,1,mc84,mf84]
    
    # Now we have fractiles and can invert. Use linear extrapolation for mlim values larger than mf.
    c16 = (Rmf-Rmc)/(mf84-mc84)
    c50 = (Rmf-Rmc)/(mf50-mc50)
    c84 = (Rmf-Rmc)/(mf16-mc16)
    cTOT = [c84, c50, c16]
    mcTOT = [mc16, mc50, mc84]
    mfTOT = [mf16, mf50, mf84]
    R16 = np.array([Rmc + c16*(x-mc84) if x>mf84 else np.interp(np.array(x),np.array(mu84),np.array(R)) for x in mlim])
    R50 = np.array([Rmc + c50*(x-mc50) if x>mf50 else np.interp(np.array(x),np.array(mu50),np.array(R)) for x in mlim])
    R84 = np.array([Rmc + c84*(x-mc16) if x>mf16 else np.interp(np.array(x),np.array(mu16),np.array(R)) for x in mlim])
    
    # <codecell>
    
    Rlim = 0.85*R50
    m50Rlim = np.array([mc50+(Rlim[i]-Rmc)/c50 if mlim[i]>mf50 else np.interp(np.array(Rlim[i]),np.array(R),np.array(mu50)) for i in range(0,len(mlim))])
    b = np.log(m50Rlim)/np.log(Rlim)
    bRSa=0.5*(np.log(R84)-np.log(R16))
    bUSa=bUthd/b    
    CR50 = mlim/R50
    Say=4*np.power(pi,2)*dry/(g*Gamma*np.power(T,2));   
    
    # <codecell>
    
    if bUthd.any()>0 and MC>0:
        # Monte Carlo approach
        st = (1./(2.*MC))
        en = (1.-(1./(2.*MC)))
        xp = np.linspace(st,en,MC)
        musample = []
        for i in range(0,len(mlim)):
            if bUthd[i]>0 and MC>0:
                musample.append(stat.lognorm.ppf(xp,bUthd[i],loc=0,scale=mlim[i]))
                musample[i][musample[i]>mlim[-1]]=mlim[-1]
            else:
                musample.append(np.repeat(mlim[i],MC))
        x=[mu16, mu50, mu84];
        Sai = []
        for i in range(0,len(mlim)):
            Sai.append([])
        rMC, SaT50, bTSa, Sa = [],[],[],[]
        
        # Estimate R-values of Sa50 and bRSa that correspond to mlim samples.    
        
        # <codecell>
        
        for i in range(0,len(mlim)):
            Sa.append(np.array([]))
            SaT50.append([])
            bTSa.append([])
            rMC.append([np.interp(musample[i],ele,R) for ele in x])
            for k in range(0,len(x)):
                rMC[i][k][musample[i]>mfTOT[k]] = Rmc+cTOT[k]*(musample[i][musample[i]>mfTOT[k]]-mcTOT[k])
                plt.plot(musample[i],rMC[i][k],marker='o')           
                
            if bUthd[i]>0:
                allSa50 = [ele*Say for ele in rMC[i][1]]
                allbSa50 = (np.log(rMC[i][0])-np.log(rMC[i][2]))/2
                for j in range(0,MC):
                    # for each potential (equiprobable) sample of mlim, get a sample of Sa-values
                    # as if we actually had N separate IDA curves, distributed according to the Sa50 and bSa50 values extracted above.
                    # In other words,generate N Sa-capacities for N different mlim realizations.
                        if allbSa50[j]>0:
                            realisation = stat.lognorm.ppf(xp,allbSa50[j],loc=0,scale=allSa50[j])
                        else:
                            realisation = np.repeat(allSa50[j],MC)
                        Sai[i].append(realisation)
                        
        for i in range(0,len(mlim)):
            # Find median of sampled Sa-values for those dcroof with bUthd>0, otherwise got to basic RGM method
            if len(Sai[i])>0:
                for j in range(1,len(Sai[i])):
                    Sai[i][j] = np.concatenate((Sai[i][j-1],Sai[i][j]))
                Sa[i] = Sai[i][-1]
                
                SaT50[i] = np.median(Sa[i])
                bTSa[i] = np.std(np.log(Sa[i]))
            else:
                SaT50[i] = 4*np.power(pi,2)*np.array(drlim[i])/(g*Gamma*CR50[i]*np.power(T,2))
                bTSa[i] = np.sqrt(np.power(bUSa[i],2) + np.power(bRSa[i],2))
    
    
    else:
    # Simplified approach.
    # Go to an R value at 85% of the R50 for a biased estimate of "b"
        SaT50 = 4*np.power(pi,2)*np.array(drlim)/(g*Gamma*CR50*np.power(T,2))
        bTSa = np.sqrt(np.power(bUSa,2) + np.power(bRSa,2))
        
    print SaT50
    print bTSa
    
    return [SaT50, bTSa]
    